# HTZG_ML
This repo contains all the machine-learning components of "Machine learning electron-phonon interactions in 2D materials" (upcoming). 

HTZG is an acronym for **H**igh-**T**hroughput **Z**acharias-**G**iustino. High-throughput refers to the nature of the study, Zacharias-Giustino refers to the old name for the Special-Displacement Method and its primary authors. 

# Requirements 
* Code was tested on Python 3.10.9. 
* Users can directly install the correct version of the Python packages through the following commands:
```
pip install -r requirements.txt
```

# Introduction

For all models trained in our work, we trained two seperate models: one on a _full_ set of input data cooresponding to material properties able to be obtained from DFT calculations, and a _reduced_ taken only from well-established "table lookup" properties of materials. Hyperparameters for the ensemble decision tree-based method are tuned separately for each data set. 

All plots and models generated by our code are already included in the repository, but re-running the scripts allow you to regenerate them. Plots will end up in the /plots directory, and trained models in the /models directory. 


# Linear Regression

We compare our more sophisticated machine learning model to ordinary least-squares linear regression. To generate plots and weights, run 

```
python htzg_linear_regression.py
```

# Extremely Randomized Trees (ERT)

Our main machine learning model are Extremely Randomized Trees (ERT)s as seen in [1]. The hyperparameter optimization step and model training are split into one script, which saves the final full-size and reduced models, and showing model performance on our data into another. 

To train the model from scratch, including hyperparameter optimization, run 

```
python htzg_train_ert.py
```
This will seperate the data into training and holdout data. We have fixed the random seeding to be consistent with our results, but you can change it on line 29 and 30 of >htzg_train_ert.py.

This will take around 25 minutes on a powerful consumer CPU. 

Then, to load the models, run them on the training and holdout data, generate truth/predictions, plots and SHAPley plots and values, run

```
python htzg_show_ert_results.py
```

# Using our Model for Inference

If you want to run your own materials with our model, an example is shown in the ```ml_inference_example.ipynb``` notebook. Our models use the ```Scikit-Learn``` library, which you can find full documentation for [here](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesRegressor.html#sklearn.ensemble.ExtraTreesRegressor.predict).

# References 

1: Geurts, Pierre, Damien Ernst, and Louis Wehenkel. "Extremely randomized trees." Machine learning 63 (2006): 3-42.
